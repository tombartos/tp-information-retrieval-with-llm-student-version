{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tombartos/tp-information-retrieval-with-llm-student-version/blob/main/1-Recherche%20d'information%20classique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugX7FayQ90_A"
      },
      "source": [
        "# Partie 1. - Recherche d'Information classique\n",
        "\n",
        "Dans cette partie, nous allons mettre en œuvre des principes et modèles classiques de Recherche d'Information. Le jeu de données est une collection de livres au format texte (.txt) de Henry Rider Haggard. Jetez un œil à ces documents dans le dossier _data_.\n",
        "\n",
        "En sortie de ce module, vous serez capable de :\n",
        "\n",
        "- Construire un index inversé ;\n",
        "- Effectuer des requêtes simples selon le modèle booléen :\n",
        "- Calculer la pondération des termes selon la méthode TF-IDF ;\n",
        "- Mettre en œuvre le modèle vectoriel de recherche d'information et y appliquer des requêtes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw1BGZgY-tvZ"
      },
      "source": [
        "### Import des bibliothèques logicielles et configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsV2t8WJd5dz"
      },
      "source": [
        "Les lignes suivantes permettent d'instancier un objet de la classe `IRSystem` représentant notre moteur de recherche et de charger les données en RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "01Fs2NMGd5dz",
        "outputId": "33b6d4dd-e35b-4f03-aa96-5c3d0495c5b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tp-information-retrieval-with-llm-student-version'...\n",
            "remote: Enumerating objects: 2254, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 2254 (delta 24), reused 33 (delta 17), pack-reused 2212 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2254/2254), 13.92 MiB | 15.78 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "/content/tp-information-retrieval-with-llm-student-version/tp-information-retrieval-with-llm-student-version/tp-information-retrieval-with-llm-student-version/tp-information-retrieval-with-llm-student-version\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Vérifie si le code est exécuté sur Google Colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    # Commandes à exécuter uniquement sur Google Colab\n",
        "    !git clone https://github.com/vincentmartin/tp-information-retrieval-with-llm-student-version.git\n",
        "    %cd tp-information-retrieval-with-llm-student-version\n",
        "else:\n",
        "    # Commandes à exécuter si ce n'est pas sur Google Colab\n",
        "    print(\"Pas sur Google Colab, ces commandes ne seront pas exécutées.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-csF9mQd5d0"
      },
      "source": [
        "#### Chargement des données\n",
        "\n",
        "Les lignes ci-dessous permettent de charger les données qui sont un ensemble de 60 livres au format texte (.txt) d'[Henry Rider Haggard](https://fr.wikipedia.org/wiki/Henry_Rider_Haggard).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZNWPECSs9wgH",
        "outputId": "1fb07d2e-8c54-4ffc-cfee-7b9aae6deefc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading in documents...\n",
            "Stemming Documents...\n",
            "Allan Quatermain 711.txt\n",
            "    Doc 1 of 60: Allan Quatermain\n",
            "Jess 5898.txt\n",
            "    Doc 2 of 60: Jess\n",
            "Ayesha, the Return of She 5228.txt\n",
            "    Doc 3 of 60: Ayesha, the Return of She\n",
            "Allan and the Ice Gods (1927) 0200201.txt\n",
            "    Doc 4 of 60: Allan and the Ice Gods (1927)\n",
            "Lysbeth, a Tale of the Dutch 5754.txt\n",
            "    Doc 5 of 60: Lysbeth, a Tale of the Dutch\n",
            "The People of the Mist 6769.txt\n",
            "    Doc 6 of 60: The People of the Mist\n",
            "Queen of the Dawn (1925) 0200381.txt\n",
            "    Doc 7 of 60: Queen of the Dawn (1925)\n",
            "Long Odds 1918.txt\n",
            "    Doc 8 of 60: Long Odds\n",
            "The Mahatma and the Hare 2764.txt\n",
            "    Doc 9 of 60: The Mahatma and the Hare\n",
            "Dawn 10892.txt\n",
            "    Doc 10 of 60: Dawn\n",
            "Marie An Episode in The Life of the late Allan Quatermain 1690.txt\n",
            "    Doc 11 of 60: Marie An Episode in The Life of the late Allan Quatermain\n",
            "Child of Storm 1711.txt\n",
            "    Doc 12 of 60: Child of Storm\n",
            "Stella Fregelius 6051.txt\n",
            "    Doc 13 of 60: Stella Fregelius\n",
            "Red Eve 3094.txt\n",
            "    Doc 14 of 60: Red Eve\n",
            "The Wanderer's Necklace 3097.txt\n",
            "    Doc 15 of 60: The Wanderer's Necklace\n",
            "Stories by English Authors Africa (Selected by Scribners) 1980.txt\n",
            "    Doc 16 of 60: Stories by English Authors Africa (Selected by Scribners)\n",
            "Maiwa's Revenge 2713.txt\n",
            "    Doc 17 of 60: Maiwa's Revenge\n",
            "She and Allan 5745.txt\n",
            "    Doc 18 of 60: She and Allan\n",
            "Montezuma's Daughter 1848.txt\n",
            "    Doc 19 of 60: Montezuma's Daughter\n",
            "Black Heart and White Heart 2842.txt\n",
            "    Doc 20 of 60: Black Heart and White Heart\n",
            "Mr. Meeson's Will 11913.txt\n",
            "    Doc 21 of 60: Mr. Meeson's Will\n",
            "Benita, an African romance 2761.txt\n",
            "    Doc 22 of 60: Benita, an African romance\n",
            "Love Eternal 3709.txt\n",
            "    Doc 23 of 60: Love Eternal\n",
            "Heu-Heu (1924) 0200191.txt\n",
            "    Doc 24 of 60: Heu-Heu (1924)\n",
            "The Witch's Head (1884) 0500791.txt\n",
            "    Doc 25 of 60: The Witch's Head (1884)\n",
            "Pearl-Maiden 5175.txt\n",
            "    Doc 26 of 60: Pearl-Maiden\n",
            "Fair Margaret 9780.txt\n",
            "    Doc 27 of 60: Fair Margaret\n",
            "A Winter Pilgrimage (1901) 0600121.txt\n",
            "    Doc 28 of 60: A Winter Pilgrimage (1901)\n",
            "Eric Brighteyes 2721.txt\n",
            "    Doc 29 of 60: Eric Brighteyes\n",
            "Morning Star 2722.txt\n",
            "    Doc 30 of 60: Morning Star\n",
            "The Ancient Allan 5746.txt\n",
            "    Doc 31 of 60: The Ancient Allan\n",
            "Beatrice 3096.txt\n",
            "    Doc 32 of 60: Beatrice\n",
            "Nada the Lily 1207.txt\n",
            "    Doc 33 of 60: Nada the Lily\n",
            "The Lady of Blossholme 3813.txt\n",
            "    Doc 34 of 60: The Lady of Blossholme\n",
            "When the World Shook 0.txt\n",
            "    Doc 35 of 60: When the World Shook\n",
            "Cleopatra 2769.txt\n",
            "    Doc 36 of 60: Cleopatra\n",
            "Allan and the Holy Flower 5174.txt\n",
            "    Doc 37 of 60: Allan and the Holy Flower\n",
            "Doctor Therne 5764.txt\n",
            "    Doc 38 of 60: Doctor Therne\n",
            "King Solomon's Mines 2166.txt\n",
            "    Doc 39 of 60: King Solomon's Mines\n",
            "Colonel Quaritch, V.C. A Tale of Country Life 11882.txt\n",
            "    Doc 40 of 60: Colonel Quaritch, V.C. A Tale of Country Life\n",
            "The Tale of Three Lions 2729.txt\n",
            "    Doc 41 of 60: The Tale of Three Lions\n",
            "She 3155.txt\n",
            "    Doc 42 of 60: She\n",
            "Regeneration 13434.txt\n",
            "    Doc 43 of 60: Regeneration\n",
            "Wisdom's Daughter (1923) 0200181.txt\n",
            "    Doc 44 of 60: Wisdom's Daughter (1923)\n",
            "The Brethren 2762.txt\n",
            "    Doc 45 of 60: The Brethren\n",
            "The Wizard 2893.txt\n",
            "    Doc 46 of 60: The Wizard\n",
            "Finished 1724.txt\n",
            "    Doc 47 of 60: Finished\n",
            "Smith and the Pharaohs, and other Tales 6073.txt\n",
            "    Doc 48 of 60: Smith and the Pharaohs, and other Tales\n",
            "The Ivory Child 2841.txt\n",
            "    Doc 49 of 60: The Ivory Child\n",
            "The World's Desire 2763.txt\n",
            "    Doc 50 of 60: The World's Desire\n",
            "The Virgin of the Sun 3153.txt\n",
            "    Doc 51 of 60: The Virgin of the Sun\n",
            "The Ghost Kings 8184.txt\n",
            "    Doc 52 of 60: The Ghost Kings\n",
            "Moon of Israel 2856.txt\n",
            "    Doc 53 of 60: Moon of Israel\n",
            "Allan's Wife 2727.txt\n",
            "    Doc 54 of 60: Allan's Wife\n",
            "Cetywayo and his White Neighbours 0.txt\n",
            "    Doc 55 of 60: Cetywayo and his White Neighbours\n",
            "A Yellow God an Idol of Africa 2857.txt\n",
            "    Doc 56 of 60: A Yellow God an Idol of Africa\n",
            "Elissa 2855.txt\n",
            "    Doc 57 of 60: Elissa\n",
            "Queen Sheba's Ring 2602.txt\n",
            "    Doc 58 of 60: Queen Sheba's Ring\n",
            "Hunter Quatermain's Story 2728.txt\n",
            "    Doc 59 of 60: Hunter Quatermain's Story\n",
            "Swallow a tale of the great trek 4074.txt\n",
            "    Doc 60 of 60: Swallow a tale of the great trek\n"
          ]
        }
      ],
      "source": [
        "from classic_ir.IRSystem import *\n",
        "\n",
        "# !rm -rf ./data/RiderHaggard/stemmed\n",
        "ir_system = IRSystem()\n",
        "ir_system.read_data('./data/RiderHaggard') # chargement des données et prétraitement des documents (stemming)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrfkliZAd5d1"
      },
      "source": [
        "### Exercice 1. - Construction de l'index inversé\n",
        "\n",
        "Ce premier exercice a pour objectif de construire l'index inversé non positionnel. L'attribut `self.inverted_index` est un tableau associatif qui associe une liste d'entiers (docIDs) à un mot (word).\n",
        "\n",
        "Documentation ici https://docs.python.org/3/library/collections.html#collections.defaultdict.\n",
        "\n",
        "Exercice : modifier la fonction `index` pour calculer l'index inversé.\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Inverted Index Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "R4Yr_ZQrd5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae0d6fe-9e69-42e7-9084-e8dcff5f8dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing...\n",
            "===== Running tests =====\n",
            "Inverted Index Test\n",
            "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Exercice 1. Indexation\n",
        "\n",
        "def index(self):\n",
        "    \"\"\"\n",
        "    Construit l'index inversé et le stocke dans self.inverted_index.\n",
        "\n",
        "    Dans le code ci-dessous, seul le dictionnaire des tokens est construit. Les postings lists sont vides.\n",
        "    \"\"\"\n",
        "    print(\"Indexing...\")\n",
        "    self.tf = defaultdict(Counter) # tf est un dictionnaire qui à un document associe un Counter de mots.\n",
        "    inverted_index = defaultdict(list) # inverted_index est un dictionnaire qui à un mot associe une liste de documents.\n",
        "    for word in self.vocab:\n",
        "        inverted_index[word] = list()\n",
        "    i=0\n",
        "    for doc in self.docs:\n",
        "      for word in doc:\n",
        "        if i not in inverted_index[word]:\n",
        "          inverted_index[word].append(i)\n",
        "      i+=1\n",
        "\n",
        "\n",
        "\n",
        "    self.inverted_index = inverted_index\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.index = index\n",
        "ir_system.index()\n",
        "run_tests(ir_system, part=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm8j-OZed5d1"
      },
      "source": [
        "### Exercice 2. - Recherche booléenne\n",
        "\n",
        "Ce deuxième exercice a pour objectif d'implémenter la recherche booléenne. La requête `query` est une liste de mots _lemmatisés_ et l'algorithme doit rechercher les documents qui contiennent TOUS ces mots.\n",
        "\n",
        "\n",
        "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Boolean Retrieval Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mfW8PxMxd5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d09f84-a5f1-4a38-c2ad-26d67aaafa95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Running tests =====\n",
            "Boolean Retrieval Test\n",
            "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Exercice 2. Recherche booléenne\n",
        "def boolean_retrieve(self, query):\n",
        "    \"\"\"\n",
        "    A partir d'une requête sous la forme d'une liste de mots *lemmatisés*,\n",
        "    retourne la liste des documents dans lesquels *tous* ces mots apparaissent (ie une requête AND).\n",
        "    Retourne une liste vide si la requête ne retourne aucun document.\n",
        "\n",
        "    Dans le code ci-dessous, tous les documents répondent.\n",
        "    \"\"\"\n",
        "    docs = list()\n",
        "    for docid in self.inverted_index[query[0]]:\n",
        "      present = True\n",
        "      for qword in query[1:]:\n",
        "        if docid not in self.inverted_index[qword]:\n",
        "          present = False\n",
        "          break     # On sort de la boucle si le doc qu'on cherche n'est pas présent dans la liste et on passe au doc suivant\n",
        "      if present:\n",
        "        docs.append(docid)\n",
        "\n",
        "    return docs\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.boolean_retrieve = boolean_retrieve\n",
        "run_tests(ir_system, part=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7DogIY9d5d2"
      },
      "source": [
        "### Exercice 3. - Calcul des poids TF-IDF des termes dans les documents\n",
        "\n",
        "Dans ce troisième exercice, l'objectif est de pré-calculer les poids TF-IDF pour chaque terme dans chaque document. Pour ce faire, appliquer la formule vue en cours. Utiliser le logarithme en base 10.\n",
        "\n",
        "\n",
        "Exercice : modifier la fonction `boolean_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "Calculating tf-idf...\n",
        "===== Running tests =====\n",
        "TF-IDF Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tests(irsys, part=None):\n",
        "    print (\"===== Running tests =====\")\n",
        "\n",
        "    ff = open('./data/queries.txt')\n",
        "    questions = [xx.strip() for xx in ff.readlines()]\n",
        "    ff.close()\n",
        "    ff = open('./data/solutions.txt')\n",
        "    solutions = [xx.strip() for xx in ff.readlines()]\n",
        "    ff.close()\n",
        "\n",
        "    epsilon = 1e-4\n",
        "    #for part in range(4):\n",
        "    points = 0\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    prob = questions[part]\n",
        "    soln = json.loads(solutions[part])\n",
        "\n",
        "    # inverted index test\n",
        "    if part == 0:\n",
        "        print (\"Inverted Index Test\")\n",
        "        words = prob.split(\", \")\n",
        "        for i, word in enumerate(words):\n",
        "            num_total += 1\n",
        "            posting = irsys.get_posting_unstemmed(word)\n",
        "            if set(posting) == set(soln[i]):\n",
        "                num_correct += 1\n",
        "\n",
        "    # boolean retrieval test\n",
        "    elif part == 1:\n",
        "        print (\"Boolean Retrieval Test\")\n",
        "        queries = prob.split(\", \")\n",
        "        for i, query in enumerate(queries):\n",
        "            num_total += 1\n",
        "            guess = irsys.query_retrieve(query)\n",
        "            if set(guess) == set(soln[i]):\n",
        "                num_correct += 1\n",
        "\n",
        "    # tfidf test\n",
        "    elif part == 2:\n",
        "        print (\"TF-IDF Test avec print\")\n",
        "        queries = prob.split(\"; \")\n",
        "        queries = [xx.split(\", \") for xx in queries]\n",
        "        queries = [(xx[0], int(xx[1])) for xx in queries]\n",
        "        for i, (word, doc) in enumerate(queries):\n",
        "            num_total += 1\n",
        "            guess = irsys.get_tfidf_unstemmed(word, doc)\n",
        "            print(f\"guess: {guess}, sol: {soln[i]}\")\n",
        "            if guess >= float(soln[i]) - epsilon and \\\n",
        "                    guess <= float(soln[i]) + epsilon:\n",
        "                num_correct += 1\n",
        "\n",
        "    # cosine similarity test\n",
        "    elif part == 3:\n",
        "        print (\"Cosine Similarity Test\")\n",
        "        queries = prob.split(\", \")\n",
        "        for i, query in enumerate(queries):\n",
        "            num_total += 1\n",
        "            ranked = irsys.query_rank(query)\n",
        "            top_rank = ranked[0]\n",
        "            print(f\"top0: {top_rank[0]}, top1: {top_rank[1]}, guess0: {soln[i][0]}, guess1: {soln[i][1]} \")\n",
        "            if top_rank[0] == soln[i][0]:\n",
        "                if top_rank[1] >= float(soln[i][1]) - epsilon and \\\n",
        "                        top_rank[1] <= float(soln[i][1]) + epsilon:\n",
        "                    num_correct += 1\n",
        "\n",
        "    feedback = \"%d/%d Correct. Accuracy: %f\" % \\\n",
        "            (num_correct, num_total, float(num_correct)/num_total)\n",
        "    if num_correct == num_total:\n",
        "        points = 3\n",
        "    elif num_correct > 0.75 * num_total:\n",
        "        points = 2\n",
        "    elif num_correct > 0:\n",
        "        points = 1\n",
        "    else:\n",
        "        points = 0\n",
        "\n",
        "    print (\"    Score: %d Feedback: %s\" % (points, feedback))"
      ],
      "metadata": {
        "id": "ugmGYfwY2Eps"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "8uHAQ2a2d5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7c9206-0bb8-48d4-ca91-32b1056ea050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating tf-idf...\n",
            "===== Running tests =====\n",
            "TF-IDF Test avec print\n",
            "guess: 0.1333773650324118, sol: 0.13337736503241182\n",
            "guess: 0.5228787452803376, sol: 0.5228787452803376\n",
            "guess: 0.23408320603336794, sol: 0.23408320603336796\n",
            "guess: 0.3916490539534377, sol: 0.39164905395343774\n",
            "guess: 0.12550382549455122, sol: 0.12550382549455125\n",
            "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Exercice 3. calcul des scores tf-idf\n",
        "from math import log\n",
        "def compute_tfidf(self):\n",
        "    \"\"\"\n",
        "    Calcule les scores tf-idf pour tous les mots de tous les documents et les stocke dans self.tfidf.\n",
        "\n",
        "    Dans le code ci-dessous, les scores tf-idf sont tous nuls.\n",
        "    \"\"\"\n",
        "    print(\"Calculating tf-idf...\")\n",
        "    self.tfidf = defaultdict(Counter)\n",
        "    N = len(self.docs)  # N = nombre de documents\n",
        "\n",
        "    occurs = []\n",
        "    for i in range(N):\n",
        "      occurs.append(Counter(self.docs[i]))\n",
        "    for word in self.vocab:\n",
        "        idftmp = log(N/len(self.inverted_index[word]), 10)\n",
        "        for i in range(N):\n",
        "            try:\n",
        "                self.tfidf[i][word] = (1+log(occurs[i][word], 10)) * idftmp\n",
        "            except ValueError:\n",
        "                self.tfidf[i][word] = 0.\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.compute_tfidf = compute_tfidf\n",
        "ir_system.compute_tfidf()\n",
        "run_tests(ir_system, part=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDNalQ1wd5d2"
      },
      "source": [
        "### Exercice 4. - Calcul de la similarité cosinus.\n",
        "\n",
        "Dans ce troisième exercice, l'objectif est de calculer la similarité cosinus entre le vecteur requête `query` et chaque vecteur document. Pour ce faire, appliquer la formule vue en cours en considérant les éléments suivants :\n",
        "- Ne considérer que la mesure TF pour calculer le poids des termes de la requête (on n'utilise pas IDF).\n",
        "- Utiliser le logarithme en base 10.\n",
        "\n",
        "Exercice : modifier la fonction `rank_retrieve` pour implémenter la recherche booléenne.\n",
        "\n",
        "Le résultat ci-dessous indique que vous avez réussi.\n",
        "```\n",
        "===== Running tests =====\n",
        "Cosine Similarity Test\n",
        "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ClAM6DM7d5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e421d02f-e30a-4766-f835-f0eb4d288765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Running tests =====\n",
            "Cosine Similarity Test\n",
            "top0: 56, top1: 0.010676611271744126, guess0: 56, guess1: 0.010676611271744128 \n",
            "top0: 59, top1: 0.05041279333939143, guess0: 59, guess1: 0.05041279333939147 \n",
            "top0: 15, top1: 0.0340578944755209, guess0: 15, guess1: 0.03405789447552096 \n",
            "top0: 24, top1: 0.015298081869538096, guess0: 24, guess1: 0.015298081869538085 \n",
            "top0: 21, top1: 0.03518293691585286, guess0: 21, guess1: 0.035182936915852864 \n",
            "    Score: 3 Feedback: 5/5 Correct. Accuracy: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Exercice 4. Similarité cosinus\n",
        "def rank_retrieve(self, query):\n",
        "    \"\"\"\n",
        "    A partir d'une requête (une liste de mots), retourne une liste de documents (classés par docID) et de scores pour la requête en appliquant la simalirité cosinus.\n",
        "\n",
        "    Dans l'exemple ci-dessous. C'est la mesure de Jaccard qui est utilisée.\n",
        "    \"\"\"\n",
        "    scores = [0.0 for _ in range(len(self.docs))]\n",
        "\n",
        "    query_set = set(query)\n",
        "\n",
        "    for d in range(len(self.docs)):\n",
        "        doc_set = set(self.docs[d])\n",
        "        intersection = len(query_set & doc_set)\n",
        "        #union = len(query_set | doc_set)\n",
        "        # Calcul de la similarité Jaccard\n",
        "        #scores[d] = intersection / union if union != 0 else 0.0\n",
        "        sum1 = 0\n",
        "        if intersection != 0:\n",
        "          for word in query_set:\n",
        "            sum1+= self.tfidf[d][word]\n",
        "        sum2 = 0\n",
        "        for tfidf in self.tfidf[d].values():\n",
        "          sum2+=tfidf**2\n",
        "        scores[d] = sum1 / (sum2**0.5)\n",
        "\n",
        "\n",
        "\n",
        "    # Tri des scores\n",
        "    ranking = [idx for idx, sim in sorted(enumerate(scores),\n",
        "                                        key=lambda pair: pair[1], reverse=True)]\n",
        "    results = []\n",
        "    for i in range(10):\n",
        "        results.append((ranking[i], scores[ranking[i]]))\n",
        "    return results\n",
        "\n",
        "# Ne pas modifier les lignes ci-dessous\n",
        "IRSystem.rank_retrieve = rank_retrieve\n",
        "run_tests(ir_system, part=3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}